{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bcd662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading Churn Modelling dataset...\n",
    "# !kaggle datasets download -d shubh0799/churn-modelling -p . --unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df31333",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6be21d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Churn_Modelling.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fdc748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping useless columns \n",
    "\n",
    "df.drop(columns = ['RowNumber', 'CustomerId', 'Surname'], axis = 1, inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8240789",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Geography.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29474155",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import joblib\n",
    "\n",
    "\n",
    "# Encode categorical variables using LabelEncoder\n",
    "geo_encoder = LabelEncoder()\n",
    "gender_encoder = LabelEncoder()\n",
    "\n",
    "df['Geography'] = geo_encoder.fit_transform(df['Geography'])\n",
    "df['Gender'] = gender_encoder.fit_transform(df['Gender'])\n",
    "\n",
    "df.head()\n",
    "\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop('Exited', axis=1)\n",
    "y = to_categorical(df['Exited'])  # For binary classification\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# ðŸ”½ Save scaler for use in your Gradio app\n",
    "joblib.dump(scaler, 'scaler.save')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b82b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89bf138",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "X = df.drop('Exited', axis=1)\n",
    "y = to_categorical(df.Exited)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82edcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting data into training set and test set\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70cf89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling data\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def8bf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Feature and label separation\n",
    "X = df.drop('Exited', axis=1)\n",
    "y = to_categorical(df['Exited'])  # If you're using to_categorical\n",
    "\n",
    "# Step 2: Scale the features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# ðŸ”½ Save the fitted scaler to use later in Gradio app\n",
    "joblib.dump(scaler, 'scaler.save')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182a5159",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "\n",
    "# initializing ann\n",
    "model = Sequential()\n",
    "\n",
    "# adding the first input layer and the first hidden layer\n",
    "model.add(Dense(16, kernel_initializer = 'normal', activation = 'relu', input_shape = (10, )))\n",
    "\n",
    "# adding batch normalization and dropout layer\n",
    "model.add(Dropout(rate = 0.1))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# adding the third hidden layer\n",
    "model.add(Dense(8, kernel_initializer = 'normal', activation = 'relu'))\n",
    "\n",
    "# adding batch normalization and dropout layer\n",
    "model.add(Dropout(rate = 0.1))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# adding the output layer\n",
    "model.add(Dense(2, kernel_initializer = 'normal', activation = 'sigmoid'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ec9ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling the model\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# fitting the model to the training set \n",
    "\n",
    "model_history = model.fit(X_train, y_train, validation_split = 0.20, validation_data = (X_test, y_test), epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d4dffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#save the model\n",
    "model.save(\"churn_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c39de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model(\"churn_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae66ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
